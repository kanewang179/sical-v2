# æ™ºèƒ½å­¦ä¹ è§„åˆ’åº”ç”¨ - æ€§èƒ½ä¼˜åŒ–æ–‡æ¡£ v0.1.1

## ğŸ“‹ æ–‡æ¡£ä¿¡æ¯

| é¡¹ç›® | æ™ºèƒ½å­¦ä¹ è§„åˆ’åº”ç”¨ æ€§èƒ½ä¼˜åŒ– |
|------|----------------------------|
| **ç‰ˆæœ¬** | v0.1.1 |
| **åç«¯æŠ€æœ¯** | Go + Gin + GORM |
| **æ›´æ–°æ—¥æœŸ** | 2024-01-15 |
| **çŠ¶æ€** | å¼€å‘ä¸­ |

## ğŸ¯ æ€§èƒ½ç›®æ ‡

### æ ¸å¿ƒæ€§èƒ½æŒ‡æ ‡

| æŒ‡æ ‡ç±»å‹ | ç›®æ ‡å€¼ | å½“å‰å€¼ | ä¼˜åŒ–ç­–ç•¥ |
|----------|--------|--------|----------|
| **APIå“åº”æ—¶é—´** | P95 < 200ms | - | ç¼“å­˜ã€æ•°æ®åº“ä¼˜åŒ– |
| **æ•°æ®åº“æŸ¥è¯¢** | P95 < 50ms | - | ç´¢å¼•ä¼˜åŒ–ã€æŸ¥è¯¢ä¼˜åŒ– |
| **å¹¶å‘å¤„ç†** | 1000+ QPS | - | è¿æ¥æ± ã€åç¨‹ä¼˜åŒ– |
| **å†…å­˜ä½¿ç”¨** | < 512MB | - | å†…å­˜æ± ã€GCä¼˜åŒ– |
| **CPUä½¿ç”¨ç‡** | < 70% | - | ç®—æ³•ä¼˜åŒ–ã€ç¼“å­˜ |
| **é”™è¯¯ç‡** | < 0.1% | - | å®¹é”™æœºåˆ¶ã€ç›‘æ§ |

### æ€§èƒ½åŸºå‡†æµ‹è¯•

```go
// æ€§èƒ½åŸºå‡†é…ç½®
type PerformanceTargets struct {
    APIResponseTime    time.Duration `json:"api_response_time"`     // P95 < 200ms
    DatabaseQueryTime  time.Duration `json:"database_query_time"`  // P95 < 50ms
    ConcurrentUsers    int           `json:"concurrent_users"`      // 1000+
    ThroughputQPS      int           `json:"throughput_qps"`        // 1000+ QPS
    MemoryUsage        int64         `json:"memory_usage"`          // < 512MB
    CPUUsage           float64       `json:"cpu_usage"`             // < 70%
    ErrorRate          float64       `json:"error_rate"`            // < 0.1%
}

var DefaultTargets = PerformanceTargets{
    APIResponseTime:   200 * time.Millisecond,
    DatabaseQueryTime: 50 * time.Millisecond,
    ConcurrentUsers:   1000,
    ThroughputQPS:     1000,
    MemoryUsage:       512 * 1024 * 1024, // 512MB
    CPUUsage:          0.7,                // 70%
    ErrorRate:         0.001,              // 0.1%
}
```

## ğŸš€ åº”ç”¨å±‚æ€§èƒ½ä¼˜åŒ–

### 1.1 HTTPæœåŠ¡å™¨ä¼˜åŒ–

#### Ginæ¡†æ¶é…ç½®ä¼˜åŒ–
```go
package server

import (
    "context"
    "net/http"
    "time"
    
    "github.com/gin-gonic/gin"
    "golang.org/x/time/rate"
)

// é«˜æ€§èƒ½æœåŠ¡å™¨é…ç½®
func NewOptimizedServer() *http.Server {
    gin.SetMode(gin.ReleaseMode)
    
    router := gin.New()
    
    // è‡ªå®šä¹‰ä¸­é—´ä»¶
    router.Use(
        gin.Recovery(),
        RequestIDMiddleware(),
        CORSMiddleware(),
        CompressionMiddleware(),
        RateLimitMiddleware(),
        MetricsMiddleware(),
    )
    
    return &http.Server{
        Addr:           ":8080",
        Handler:        router,
        ReadTimeout:    10 * time.Second,
        WriteTimeout:   10 * time.Second,
        IdleTimeout:    60 * time.Second,
        MaxHeaderBytes: 1 << 20, // 1MB
    }
}

// å‹ç¼©ä¸­é—´ä»¶
func CompressionMiddleware() gin.HandlerFunc {
    return gin.HandlerFunc(func(c *gin.Context) {
        // åªå¯¹å¤§äº1KBçš„å“åº”è¿›è¡Œå‹ç¼©
        if c.Request.Header.Get("Accept-Encoding") != "" {
            c.Header("Content-Encoding", "gzip")
        }
        c.Next()
    })
}

// é™æµä¸­é—´ä»¶
func RateLimitMiddleware() gin.HandlerFunc {
    limiter := rate.NewLimiter(rate.Limit(100), 200) // 100 QPS, çªå‘200
    
    return gin.HandlerFunc(func(c *gin.Context) {
        if !limiter.Allow() {
            c.JSON(http.StatusTooManyRequests, gin.H{
                "error": "Rate limit exceeded",
            })
            c.Abort()
            return
        }
        c.Next()
    })
}
```

#### è¿æ¥æ± ä¼˜åŒ–
```go
package config

import (
    "net/http"
    "time"
)

// HTTPå®¢æˆ·ç«¯è¿æ¥æ± é…ç½®
func NewOptimizedHTTPClient() *http.Client {
    transport := &http.Transport{
        MaxIdleConns:        100,              // æœ€å¤§ç©ºé—²è¿æ¥æ•°
        MaxIdleConnsPerHost: 10,               // æ¯ä¸ªä¸»æœºæœ€å¤§ç©ºé—²è¿æ¥æ•°
        MaxConnsPerHost:     100,              // æ¯ä¸ªä¸»æœºæœ€å¤§è¿æ¥æ•°
        IdleConnTimeout:     90 * time.Second, // ç©ºé—²è¿æ¥è¶…æ—¶
        TLSHandshakeTimeout: 10 * time.Second, // TLSæ¡æ‰‹è¶…æ—¶
        DisableCompression:  false,            // å¯ç”¨å‹ç¼©
    }
    
    return &http.Client{
        Transport: transport,
        Timeout:   30 * time.Second,
    }
}
```

### 1.2 å†…å­˜ç®¡ç†ä¼˜åŒ–

#### å¯¹è±¡æ± æ¨¡å¼
```go
package pool

import (
    "sync"
    "bytes"
)

// å­—èŠ‚ç¼“å†²æ± 
var ByteBufferPool = sync.Pool{
    New: func() interface{} {
        return &bytes.Buffer{}
    },
}

// è·å–ç¼“å†²åŒº
func GetBuffer() *bytes.Buffer {
    return ByteBufferPool.Get().(*bytes.Buffer)
}

// å½’è¿˜ç¼“å†²åŒº
func PutBuffer(buf *bytes.Buffer) {
    buf.Reset()
    ByteBufferPool.Put(buf)
}

// å“åº”å¯¹è±¡æ± 
type Response struct {
    Status  string      `json:"status"`
    Message string      `json:"message"`
    Data    interface{} `json:"data,omitempty"`
}

var ResponsePool = sync.Pool{
    New: func() interface{} {
        return &Response{}
    },
}

func GetResponse() *Response {
    return ResponsePool.Get().(*Response)
}

func PutResponse(resp *Response) {
    resp.Status = ""
    resp.Message = ""
    resp.Data = nil
    ResponsePool.Put(resp)
}
```

#### GCä¼˜åŒ–é…ç½®
```go
package main

import (
    "runtime"
    "runtime/debug"
    "time"
)

func init() {
    // è®¾ç½®GCç›®æ ‡ç™¾åˆ†æ¯”
    debug.SetGCPercent(100)
    
    // è®¾ç½®æœ€å¤§å¤„ç†å™¨æ•°
    runtime.GOMAXPROCS(runtime.NumCPU())
    
    // å®šæœŸå¼ºåˆ¶GCï¼ˆåœ¨ä½è´Ÿè½½æ—¶ï¼‰
    go func() {
        ticker := time.NewTicker(5 * time.Minute)
        defer ticker.Stop()
        
        for range ticker.C {
            runtime.GC()
        }
    }()
}

// å†…å­˜ç›‘æ§
func GetMemoryStats() runtime.MemStats {
    var m runtime.MemStats
    runtime.ReadMemStats(&m)
    return m
}
```

## ğŸ—„ï¸ æ•°æ®åº“æ€§èƒ½ä¼˜åŒ–

### 2.1 GORMé…ç½®ä¼˜åŒ–

#### è¿æ¥æ± é…ç½®
```go
package database

import (
    "time"
    
    "gorm.io/driver/postgres"
    "gorm.io/gorm"
    "gorm.io/gorm/logger"
)

func NewOptimizedDB(dsn string) (*gorm.DB, error) {
    config := &gorm.Config{
        Logger: logger.Default.LogMode(logger.Silent), // ç”Ÿäº§ç¯å¢ƒå…³é—­SQLæ—¥å¿—
        PrepareStmt: true,                             // é¢„ç¼–è¯‘è¯­å¥
        DisableForeignKeyConstraintWhenMigrating: true, // è¿ç§»æ—¶ç¦ç”¨å¤–é”®çº¦æŸ
    }
    
    db, err := gorm.Open(postgres.Open(dsn), config)
    if err != nil {
        return nil, err
    }
    
    sqlDB, err := db.DB()
    if err != nil {
        return nil, err
    }
    
    // è¿æ¥æ± é…ç½®
    sqlDB.SetMaxIdleConns(10)                   // æœ€å¤§ç©ºé—²è¿æ¥æ•°
    sqlDB.SetMaxOpenConns(100)                  // æœ€å¤§æ‰“å¼€è¿æ¥æ•°
    sqlDB.SetConnMaxLifetime(time.Hour)         // è¿æ¥æœ€å¤§ç”Ÿå­˜æ—¶é—´
    sqlDB.SetConnMaxIdleTime(10 * time.Minute)  // è¿æ¥æœ€å¤§ç©ºé—²æ—¶é—´
    
    return db, nil
}
```

#### æŸ¥è¯¢ä¼˜åŒ–
```go
package repository

import (
    "context"
    "time"
    
    "gorm.io/gorm"
    "sical-backend/internal/domain"
)

type OptimizedUserRepository struct {
    db *gorm.DB
}

// æ‰¹é‡æŸ¥è¯¢ä¼˜åŒ–
func (r *OptimizedUserRepository) GetUsersByIDs(ctx context.Context, ids []uint64) ([]*domain.User, error) {
    var users []*domain.User
    
    // ä½¿ç”¨INæŸ¥è¯¢ï¼Œé™åˆ¶æ‰¹é‡å¤§å°
    const batchSize = 100
    for i := 0; i < len(ids); i += batchSize {
        end := i + batchSize
        if end > len(ids) {
            end = len(ids)
        }
        
        var batch []*domain.User
        err := r.db.WithContext(ctx).
            Select("id, username, email, status, created_at"). // åªé€‰æ‹©éœ€è¦çš„å­—æ®µ
            Where("id IN ?", ids[i:end]).
            Find(&batch).Error
        
        if err != nil {
            return nil, err
        }
        
        users = append(users, batch...)
    }
    
    return users, nil
}

// åˆ†é¡µæŸ¥è¯¢ä¼˜åŒ–
func (r *OptimizedUserRepository) GetUsersWithPagination(ctx context.Context, offset, limit int) ([]*domain.User, int64, error) {
    var users []*domain.User
    var total int64
    
    // å¹¶è¡Œæ‰§è¡Œè®¡æ•°å’ŒæŸ¥è¯¢
    errChan := make(chan error, 2)
    
    // è®¡æ•°æŸ¥è¯¢
    go func() {
        err := r.db.WithContext(ctx).
            Model(&domain.User{}).
            Where("deleted_at IS NULL").
            Count(&total).Error
        errChan <- err
    }()
    
    // æ•°æ®æŸ¥è¯¢
    go func() {
        err := r.db.WithContext(ctx).
            Select("id, username, email, status, created_at").
            Where("deleted_at IS NULL").
            Order("created_at DESC").
            Offset(offset).
            Limit(limit).
            Find(&users).Error
        errChan <- err
    }()
    
    // ç­‰å¾…ä¸¤ä¸ªæŸ¥è¯¢å®Œæˆ
    for i := 0; i < 2; i++ {
        if err := <-errChan; err != nil {
            return nil, 0, err
        }
    }
    
    return users, total, nil
}

// é¢„åŠ è½½ä¼˜åŒ–
func (r *OptimizedUserRepository) GetUserWithGoals(ctx context.Context, userID uint64) (*domain.User, error) {
    var user domain.User
    
    err := r.db.WithContext(ctx).
        Preload("LearningGoals", func(db *gorm.DB) *gorm.DB {
            return db.Select("id, user_id, title, status, created_at"). // åªé¢„åŠ è½½éœ€è¦çš„å­—æ®µ
                Where("status = ?", "active").
                Order("created_at DESC")
        }).
        First(&user, userID).Error
    
    return &user, err
}
```

### 2.2 ç´¢å¼•ä¼˜åŒ–ç­–ç•¥

#### å¤åˆç´¢å¼•è®¾è®¡
```sql
-- ç”¨æˆ·è¡¨ç´¢å¼•ä¼˜åŒ–
CREATE INDEX CONCURRENTLY idx_users_email_status ON users(email, status) WHERE deleted_at IS NULL;
CREATE INDEX CONCURRENTLY idx_users_created_at ON users(created_at DESC) WHERE deleted_at IS NULL;
CREATE INDEX CONCURRENTLY idx_users_status_created ON users(status, created_at DESC) WHERE deleted_at IS NULL;

-- å­¦ä¹ ç›®æ ‡è¡¨ç´¢å¼•ä¼˜åŒ–
CREATE INDEX CONCURRENTLY idx_learning_goals_user_status ON learning_goals(user_id, status, created_at DESC);
CREATE INDEX CONCURRENTLY idx_learning_goals_category_status ON learning_goals(category, status) WHERE deleted_at IS NULL;
CREATE INDEX CONCURRENTLY idx_learning_goals_target_date ON learning_goals(target_date) WHERE status = 'active';

-- å­¦ä¹ è·¯å¾„è¡¨ç´¢å¼•ä¼˜åŒ–
CREATE INDEX CONCURRENTLY idx_learning_paths_goal_order ON learning_paths(learning_goal_id, order_index);
CREATE INDEX CONCURRENTLY idx_learning_paths_status_updated ON learning_paths(status, updated_at DESC);

-- çŸ¥è¯†ç‚¹è¡¨ç´¢å¼•ä¼˜åŒ–
CREATE INDEX CONCURRENTLY idx_knowledge_points_path_order ON knowledge_points(learning_path_id, order_index);
CREATE INDEX CONCURRENTLY idx_knowledge_points_difficulty ON knowledge_points(difficulty_level, category);

-- è¯„ä¼°æµ‹è¯•è¡¨ç´¢å¼•ä¼˜åŒ–
CREATE INDEX CONCURRENTLY idx_assessments_user_created ON assessments(user_id, created_at DESC);
CREATE INDEX CONCURRENTLY idx_assessments_type_status ON assessments(assessment_type, status);

-- è¯„è®ºè¡¨ç´¢å¼•ä¼˜åŒ–
CREATE INDEX CONCURRENTLY idx_comments_target_created ON comments(target_type, target_id, created_at DESC);
CREATE INDEX CONCURRENTLY idx_comments_user_created ON comments(user_id, created_at DESC);
```

#### éƒ¨åˆ†ç´¢å¼•ä¼˜åŒ–
```sql
-- åªä¸ºæ´»è·ƒç”¨æˆ·åˆ›å»ºç´¢å¼•
CREATE INDEX CONCURRENTLY idx_active_users_email ON users(email) WHERE status = 'active' AND deleted_at IS NULL;

-- åªä¸ºæœªå®Œæˆçš„å­¦ä¹ ç›®æ ‡åˆ›å»ºç´¢å¼•
CREATE INDEX CONCURRENTLY idx_incomplete_goals ON learning_goals(user_id, target_date) 
WHERE status IN ('active', 'in_progress') AND deleted_at IS NULL;

-- åªä¸ºæœ€è¿‘çš„è¯„ä¼°åˆ›å»ºç´¢å¼•
CREATE INDEX CONCURRENTLY idx_recent_assessments ON assessments(user_id, score) 
WHERE created_at > NOW() - INTERVAL '30 days';
```

### 2.3 æŸ¥è¯¢æ€§èƒ½ç›‘æ§

#### æ…¢æŸ¥è¯¢ç›‘æ§
```go
package monitoring

import (
    "context"
    "time"
    
    "github.com/prometheus/client_golang/prometheus"
    "gorm.io/gorm"
    "gorm.io/gorm/logger"
)

// æ•°æ®åº“æ€§èƒ½æŒ‡æ ‡
var (
    dbQueryDuration = prometheus.NewHistogramVec(
        prometheus.HistogramOpts{
            Name: "db_query_duration_seconds",
            Help: "Database query duration in seconds",
            Buckets: []float64{0.001, 0.005, 0.01, 0.025, 0.05, 0.1, 0.25, 0.5, 1.0},
        },
        []string{"operation", "table"},
    )
    
    dbQueryTotal = prometheus.NewCounterVec(
        prometheus.CounterOpts{
            Name: "db_queries_total",
            Help: "Total number of database queries",
        },
        []string{"operation", "table", "status"},
    )
)

// è‡ªå®šä¹‰GORMæ—¥å¿—è®°å½•å™¨
type MetricsLogger struct {
    logger.Interface
}

func (l *MetricsLogger) Trace(ctx context.Context, begin time.Time, fc func() (sql string, rowsAffected int64), err error) {
    elapsed := time.Since(begin)
    sql, rows := fc()
    
    // è§£æSQLè·å–æ“ä½œç±»å‹å’Œè¡¨å
    operation, table := parseSQLOperation(sql)
    
    // è®°å½•æŒ‡æ ‡
    dbQueryDuration.WithLabelValues(operation, table).Observe(elapsed.Seconds())
    
    status := "success"
    if err != nil {
        status = "error"
    }
    dbQueryTotal.WithLabelValues(operation, table, status).Inc()
    
    // è®°å½•æ…¢æŸ¥è¯¢
    if elapsed > 100*time.Millisecond {
        logger.Default.Warn(ctx, "Slow query detected", 
            "duration", elapsed,
            "sql", sql,
            "rows", rows,
            "error", err,
        )
    }
    
    // è°ƒç”¨åŸå§‹æ—¥å¿—è®°å½•å™¨
    l.Interface.Trace(ctx, begin, fc, err)
}

func parseSQLOperation(sql string) (operation, table string) {
    // ç®€å•çš„SQLè§£æé€»è¾‘
    // å®é™…å®ç°ä¸­å¯ä»¥ä½¿ç”¨æ›´å¤æ‚çš„SQLè§£æå™¨
    if strings.HasPrefix(strings.ToUpper(sql), "SELECT") {
        return "SELECT", extractTableName(sql)
    } else if strings.HasPrefix(strings.ToUpper(sql), "INSERT") {
        return "INSERT", extractTableName(sql)
    } else if strings.HasPrefix(strings.ToUpper(sql), "UPDATE") {
        return "UPDATE", extractTableName(sql)
    } else if strings.HasPrefix(strings.ToUpper(sql), "DELETE") {
        return "DELETE", extractTableName(sql)
    }
    return "UNKNOWN", "unknown"
}
```

## ğŸ”„ ç¼“å­˜ä¼˜åŒ–ç­–ç•¥

### 3.1 Redisç¼“å­˜é…ç½®

#### è¿æ¥æ± ä¼˜åŒ–
```go
package cache

import (
    "context"
    "encoding/json"
    "time"
    
    "github.com/redis/go-redis/v9"
)

// ä¼˜åŒ–çš„Rediså®¢æˆ·ç«¯é…ç½®
func NewOptimizedRedisClient(addr, password string, db int) *redis.Client {
    return redis.NewClient(&redis.Options{
        Addr:         addr,
        Password:     password,
        DB:           db,
        PoolSize:     100,                    // è¿æ¥æ± å¤§å°
        MinIdleConns: 10,                     // æœ€å°ç©ºé—²è¿æ¥æ•°
        MaxIdleConns: 50,                     // æœ€å¤§ç©ºé—²è¿æ¥æ•°
        PoolTimeout:  4 * time.Second,        // è¿æ¥æ± è¶…æ—¶
        IdleTimeout:  5 * time.Minute,        // ç©ºé—²è¿æ¥è¶…æ—¶
        ReadTimeout:  3 * time.Second,        // è¯»å–è¶…æ—¶
        WriteTimeout: 3 * time.Second,        // å†™å…¥è¶…æ—¶
        DialTimeout:  5 * time.Second,        // è¿æ¥è¶…æ—¶
    })
}

// ç¼“å­˜ç®¡ç†å™¨
type CacheManager struct {
    client *redis.Client
}

func NewCacheManager(client *redis.Client) *CacheManager {
    return &CacheManager{client: client}
}

// å¤šçº§ç¼“å­˜ç­–ç•¥
func (c *CacheManager) GetWithFallback(ctx context.Context, key string, fallback func() (interface{}, error), ttl time.Duration) (interface{}, error) {
    // 1. å°è¯•ä»ç¼“å­˜è·å–
    cached, err := c.client.Get(ctx, key).Result()
    if err == nil {
        var result interface{}
        if err := json.Unmarshal([]byte(cached), &result); err == nil {
            return result, nil
        }
    }
    
    // 2. ç¼“å­˜æœªå‘½ä¸­ï¼Œè°ƒç”¨fallbackå‡½æ•°
    data, err := fallback()
    if err != nil {
        return nil, err
    }
    
    // 3. å¼‚æ­¥å†™å…¥ç¼“å­˜
    go func() {
        jsonData, err := json.Marshal(data)
        if err == nil {
            c.client.Set(context.Background(), key, jsonData, ttl)
        }
    }()
    
    return data, nil
}

// æ‰¹é‡ç¼“å­˜æ“ä½œ
func (c *CacheManager) MGet(ctx context.Context, keys []string) (map[string]interface{}, error) {
    if len(keys) == 0 {
        return make(map[string]interface{}), nil
    }
    
    values, err := c.client.MGet(ctx, keys...).Result()
    if err != nil {
        return nil, err
    }
    
    result := make(map[string]interface{})
    for i, value := range values {
        if value != nil {
            var data interface{}
            if err := json.Unmarshal([]byte(value.(string)), &data); err == nil {
                result[keys[i]] = data
            }
        }
    }
    
    return result, nil
}

// ç¼“å­˜é¢„çƒ­
func (c *CacheManager) Warmup(ctx context.Context) error {
    // é¢„çƒ­çƒ­ç‚¹æ•°æ®
    hotKeys := []string{
        "popular_learning_goals",
        "trending_knowledge_points",
        "system_statistics",
    }
    
    for _, key := range hotKeys {
        // æ£€æŸ¥ç¼“å­˜æ˜¯å¦å­˜åœ¨
        exists, err := c.client.Exists(ctx, key).Result()
        if err != nil || exists == 0 {
            // æ ¹æ®keyç±»å‹åŠ è½½æ•°æ®
            switch key {
            case "popular_learning_goals":
                // åŠ è½½çƒ­é—¨å­¦ä¹ ç›®æ ‡
            case "trending_knowledge_points":
                // åŠ è½½çƒ­é—¨çŸ¥è¯†ç‚¹
            case "system_statistics":
                // åŠ è½½ç³»ç»Ÿç»Ÿè®¡æ•°æ®
            }
        }
    }
    
    return nil
}
```

### 3.2 åº”ç”¨å±‚ç¼“å­˜

#### æœ¬åœ°ç¼“å­˜å®ç°
```go
package cache

import (
    "sync"
    "time"
)

// LRUç¼“å­˜å®ç°
type LRUCache struct {
    capacity int
    cache    map[string]*Node
    head     *Node
    tail     *Node
    mutex    sync.RWMutex
}

type Node struct {
    key      string
    value    interface{}
    expireAt time.Time
    prev     *Node
    next     *Node
}

func NewLRUCache(capacity int) *LRUCache {
    cache := &LRUCache{
        capacity: capacity,
        cache:    make(map[string]*Node),
    }
    
    // åˆ›å»ºå“¨å…µèŠ‚ç‚¹
    cache.head = &Node{}
    cache.tail = &Node{}
    cache.head.next = cache.tail
    cache.tail.prev = cache.head
    
    // å¯åŠ¨æ¸…ç†åç¨‹
    go cache.cleanup()
    
    return cache
}

func (c *LRUCache) Get(key string) (interface{}, bool) {
    c.mutex.RLock()
    defer c.mutex.RUnlock()
    
    if node, exists := c.cache[key]; exists {
        // æ£€æŸ¥æ˜¯å¦è¿‡æœŸ
        if time.Now().After(node.expireAt) {
            c.removeNode(node)
            delete(c.cache, key)
            return nil, false
        }
        
        // ç§»åŠ¨åˆ°å¤´éƒ¨
        c.moveToHead(node)
        return node.value, true
    }
    
    return nil, false
}

func (c *LRUCache) Set(key string, value interface{}, ttl time.Duration) {
    c.mutex.Lock()
    defer c.mutex.Unlock()
    
    expireAt := time.Now().Add(ttl)
    
    if node, exists := c.cache[key]; exists {
        // æ›´æ–°ç°æœ‰èŠ‚ç‚¹
        node.value = value
        node.expireAt = expireAt
        c.moveToHead(node)
    } else {
        // åˆ›å»ºæ–°èŠ‚ç‚¹
        newNode := &Node{
            key:      key,
            value:    value,
            expireAt: expireAt,
        }
        
        c.cache[key] = newNode
        c.addToHead(newNode)
        
        // æ£€æŸ¥å®¹é‡
        if len(c.cache) > c.capacity {
            tail := c.removeTail()
            delete(c.cache, tail.key)
        }
    }
}

// å®šæœŸæ¸…ç†è¿‡æœŸæ•°æ®
func (c *LRUCache) cleanup() {
    ticker := time.NewTicker(1 * time.Minute)
    defer ticker.Stop()
    
    for range ticker.C {
        c.mutex.Lock()
        now := time.Now()
        
        for key, node := range c.cache {
            if now.After(node.expireAt) {
                c.removeNode(node)
                delete(c.cache, key)
            }
        }
        
        c.mutex.Unlock()
    }
}
```

### 3.3 ç¼“å­˜ç­–ç•¥ä¼˜åŒ–

#### æ™ºèƒ½ç¼“å­˜é”®è®¾è®¡
```go
package cache

import (
    "crypto/md5"
    "fmt"
    "sort"
    "strings"
)

// ç¼“å­˜é”®ç”Ÿæˆå™¨
type KeyGenerator struct {
    prefix string
}

func NewKeyGenerator(prefix string) *KeyGenerator {
    return &KeyGenerator{prefix: prefix}
}

// ç”¨æˆ·ç›¸å…³ç¼“å­˜é”®
func (kg *KeyGenerator) UserProfileKey(userID uint64) string {
    return fmt.Sprintf("%s:user:profile:%d", kg.prefix, userID)
}

func (kg *KeyGenerator) UserGoalsKey(userID uint64, status string) string {
    return fmt.Sprintf("%s:user:goals:%d:%s", kg.prefix, userID, status)
}

// å­¦ä¹ è·¯å¾„ç¼“å­˜é”®
func (kg *KeyGenerator) LearningPathKey(goalID uint64) string {
    return fmt.Sprintf("%s:learning:path:%d", kg.prefix, goalID)
}

// å¤æ‚æŸ¥è¯¢ç¼“å­˜é”®ï¼ˆåŸºäºå‚æ•°å“ˆå¸Œï¼‰
func (kg *KeyGenerator) QueryKey(operation string, params map[string]interface{}) string {
    // å¯¹å‚æ•°è¿›è¡Œæ’åºä»¥ç¡®ä¿ä¸€è‡´æ€§
    var keys []string
    for k := range params {
        keys = append(keys, k)
    }
    sort.Strings(keys)
    
    var parts []string
    for _, k := range keys {
        parts = append(parts, fmt.Sprintf("%s=%v", k, params[k]))
    }
    
    paramStr := strings.Join(parts, "&")
    hash := fmt.Sprintf("%x", md5.Sum([]byte(paramStr)))
    
    return fmt.Sprintf("%s:query:%s:%s", kg.prefix, operation, hash)
}

// åˆ†é¡µç¼“å­˜é”®
func (kg *KeyGenerator) PaginationKey(resource string, page, limit int, filters map[string]interface{}) string {
    filterHash := ""
    if len(filters) > 0 {
        filterHash = kg.hashFilters(filters)
    }
    
    return fmt.Sprintf("%s:page:%s:%d:%d:%s", kg.prefix, resource, page, limit, filterHash)
}

func (kg *KeyGenerator) hashFilters(filters map[string]interface{}) string {
    var keys []string
    for k := range filters {
        keys = append(keys, k)
    }
    sort.Strings(keys)
    
    var parts []string
    for _, k := range keys {
        parts = append(parts, fmt.Sprintf("%s=%v", k, filters[k]))
    }
    
    return fmt.Sprintf("%x", md5.Sum([]byte(strings.Join(parts, "&"))))
}
```

## ğŸ“Š æ€§èƒ½ç›‘æ§ä¸åˆ†æ

### 4.1 åº”ç”¨æ€§èƒ½ç›‘æ§

#### PrometheusæŒ‡æ ‡æ”¶é›†
```go
package metrics

import (
    "time"
    
    "github.com/gin-gonic/gin"
    "github.com/prometheus/client_golang/prometheus"
    "github.com/prometheus/client_golang/prometheus/promauto"
)

// åº”ç”¨æ€§èƒ½æŒ‡æ ‡
var (
    // HTTPè¯·æ±‚æŒ‡æ ‡
    httpRequestsTotal = promauto.NewCounterVec(
        prometheus.CounterOpts{
            Name: "http_requests_total",
            Help: "Total number of HTTP requests",
        },
        []string{"method", "endpoint", "status"},
    )
    
    httpRequestDuration = promauto.NewHistogramVec(
        prometheus.HistogramOpts{
            Name: "http_request_duration_seconds",
            Help: "HTTP request duration in seconds",
            Buckets: []float64{0.001, 0.005, 0.01, 0.025, 0.05, 0.1, 0.25, 0.5, 1.0, 2.5, 5.0},
        },
        []string{"method", "endpoint"},
    )
    
    // ä¸šåŠ¡æŒ‡æ ‡
    activeUsers = promauto.NewGauge(
        prometheus.GaugeOpts{
            Name: "active_users_total",
            Help: "Number of active users",
        },
    )
    
    learningGoalsCreated = promauto.NewCounterVec(
        prometheus.CounterOpts{
            Name: "learning_goals_created_total",
            Help: "Total number of learning goals created",
        },
        []string{"category"},
    )
    
    // ç³»ç»Ÿèµ„æºæŒ‡æ ‡
    memoryUsage = promauto.NewGauge(
        prometheus.GaugeOpts{
            Name: "memory_usage_bytes",
            Help: "Memory usage in bytes",
        },
    )
    
    goroutineCount = promauto.NewGauge(
        prometheus.GaugeOpts{
            Name: "goroutines_total",
            Help: "Number of goroutines",
        },
    )
)

// HTTPæŒ‡æ ‡ä¸­é—´ä»¶
func MetricsMiddleware() gin.HandlerFunc {
    return gin.HandlerFunc(func(c *gin.Context) {
        start := time.Now()
        
        c.Next()
        
        duration := time.Since(start)
        status := fmt.Sprintf("%d", c.Writer.Status())
        
        httpRequestsTotal.WithLabelValues(
            c.Request.Method,
            c.FullPath(),
            status,
        ).Inc()
        
        httpRequestDuration.WithLabelValues(
            c.Request.Method,
            c.FullPath(),
        ).Observe(duration.Seconds())
    })
}

// ç³»ç»ŸæŒ‡æ ‡æ”¶é›†å™¨
func StartMetricsCollector() {
    go func() {
        ticker := time.NewTicker(30 * time.Second)
        defer ticker.Stop()
        
        for range ticker.C {
            // æ”¶é›†å†…å­˜ä½¿ç”¨æƒ…å†µ
            var m runtime.MemStats
            runtime.ReadMemStats(&m)
            memoryUsage.Set(float64(m.Alloc))
            
            // æ”¶é›†åç¨‹æ•°é‡
            goroutineCount.Set(float64(runtime.NumGoroutine()))
            
            // æ”¶é›†æ´»è·ƒç”¨æˆ·æ•°ï¼ˆéœ€è¦ä»æ•°æ®åº“æˆ–ç¼“å­˜è·å–ï¼‰
            // activeUsers.Set(float64(getActiveUserCount()))
        }
    }()
}
```

### 4.2 æ€§èƒ½åˆ†æå·¥å…·

#### pprofæ€§èƒ½åˆ†æ
```go
package profiling

import (
    "net/http"
    _ "net/http/pprof"
    "runtime"
    "time"
)

// å¯ç”¨æ€§èƒ½åˆ†æ
func EnableProfiling(addr string) {
    // è®¾ç½®é‡‡æ ·ç‡
    runtime.SetMutexProfileFraction(1)
    runtime.SetBlockProfileRate(1)
    
    // å¯åŠ¨pprofæœåŠ¡å™¨
    go func() {
        http.ListenAndServe(addr, nil)
    }()
}

// è‡ªåŠ¨æ€§èƒ½åˆ†æ
func StartAutoProfiling() {
    go func() {
        ticker := time.NewTicker(10 * time.Minute)
        defer ticker.Stop()
        
        for range ticker.C {
            // è‡ªåŠ¨ç”ŸæˆCPU profile
            generateCPUProfile()
            
            // è‡ªåŠ¨ç”Ÿæˆå†…å­˜profile
            generateMemProfile()
        }
    }()
}

func generateCPUProfile() {
    // å®ç°CPU profileç”Ÿæˆé€»è¾‘
}

func generateMemProfile() {
    // å®ç°å†…å­˜profileç”Ÿæˆé€»è¾‘
}
```

### 4.3 æ€§èƒ½å‘Šè­¦é…ç½®

#### Prometheuså‘Šè­¦è§„åˆ™
```yaml
# alerts.yml
groups:
- name: sical-backend-performance
  rules:
  # APIå“åº”æ—¶é—´å‘Šè­¦
  - alert: HighAPIResponseTime
    expr: histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m])) > 0.2
    for: 2m
    labels:
      severity: warning
    annotations:
      summary: "APIå“åº”æ—¶é—´è¿‡é«˜"
      description: "95%çš„APIè¯·æ±‚å“åº”æ—¶é—´è¶…è¿‡200msï¼Œå½“å‰å€¼: {{ $value }}s"
  
  # é”™è¯¯ç‡å‘Šè­¦
  - alert: HighErrorRate
    expr: rate(http_requests_total{status=~"5.."}[5m]) / rate(http_requests_total[5m]) > 0.01
    for: 1m
    labels:
      severity: critical
    annotations:
      summary: "APIé”™è¯¯ç‡è¿‡é«˜"
      description: "APIé”™è¯¯ç‡è¶…è¿‡1%ï¼Œå½“å‰å€¼: {{ $value | humanizePercentage }}"
  
  # å†…å­˜ä½¿ç”¨å‘Šè­¦
  - alert: HighMemoryUsage
    expr: memory_usage_bytes > 500 * 1024 * 1024  # 500MB
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "å†…å­˜ä½¿ç”¨è¿‡é«˜"
      description: "åº”ç”¨å†…å­˜ä½¿ç”¨è¶…è¿‡500MBï¼Œå½“å‰å€¼: {{ $value | humanizeBytes }}"
  
  # åç¨‹æ•°é‡å‘Šè­¦
  - alert: HighGoroutineCount
    expr: goroutines_total > 1000
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "åç¨‹æ•°é‡è¿‡å¤š"
      description: "åç¨‹æ•°é‡è¶…è¿‡1000ï¼Œå½“å‰å€¼: {{ $value }}"
  
  # æ•°æ®åº“è¿æ¥å‘Šè­¦
  - alert: DatabaseConnectionIssue
    expr: rate(db_queries_total{status="error"}[5m]) > 0.1
    for: 2m
    labels:
      severity: critical
    annotations:
      summary: "æ•°æ®åº“è¿æ¥å¼‚å¸¸"
      description: "æ•°æ®åº“æŸ¥è¯¢é”™è¯¯ç‡è¿‡é«˜ï¼Œå½“å‰å€¼: {{ $value }}"
```

## ğŸ”§ æ€§èƒ½è°ƒä¼˜æœ€ä½³å®è·µ

### 5.1 ä»£ç å±‚é¢ä¼˜åŒ–

#### é¿å…å¸¸è§æ€§èƒ½é™·é˜±
```go
// âŒ é”™è¯¯ç¤ºä¾‹ï¼šå­—ç¬¦ä¸²æ‹¼æ¥
func badStringConcat(items []string) string {
    result := ""
    for _, item := range items {
        result += item + ","
    }
    return result
}

// âœ… æ­£ç¡®ç¤ºä¾‹ï¼šä½¿ç”¨strings.Builder
func goodStringConcat(items []string) string {
    var builder strings.Builder
    builder.Grow(len(items) * 10) // é¢„åˆ†é…å®¹é‡
    
    for i, item := range items {
        if i > 0 {
            builder.WriteString(",")
        }
        builder.WriteString(item)
    }
    return builder.String()
}

// âŒ é”™è¯¯ç¤ºä¾‹ï¼šé¢‘ç¹çš„å†…å­˜åˆ†é…
func badSliceAppend() []int {
    var result []int
    for i := 0; i < 10000; i++ {
        result = append(result, i)
    }
    return result
}

// âœ… æ­£ç¡®ç¤ºä¾‹ï¼šé¢„åˆ†é…åˆ‡ç‰‡å®¹é‡
func goodSliceAppend() []int {
    result := make([]int, 0, 10000) // é¢„åˆ†é…å®¹é‡
    for i := 0; i < 10000; i++ {
        result = append(result, i)
    }
    return result
}

// âŒ é”™è¯¯ç¤ºä¾‹ï¼šä¸å¿…è¦çš„JSONåºåˆ—åŒ–
func badJSONHandling(data interface{}) string {
    jsonData, _ := json.Marshal(data)
    return string(jsonData)
}

// âœ… æ­£ç¡®ç¤ºä¾‹ï¼šä½¿ç”¨å¯¹è±¡æ± 
func goodJSONHandling(data interface{}) string {
    buf := pool.GetBuffer()
    defer pool.PutBuffer(buf)
    
    encoder := json.NewEncoder(buf)
    encoder.Encode(data)
    return buf.String()
}
```

### 5.2 å¹¶å‘ä¼˜åŒ–

#### åç¨‹æ± å®ç°
```go
package worker

import (
    "context"
    "sync"
)

type WorkerPool struct {
    workerCount int
    jobQueue    chan Job
    workers     []*Worker
    wg          sync.WaitGroup
    ctx         context.Context
    cancel      context.CancelFunc
}

type Job func() error

type Worker struct {
    id       int
    jobQueue chan Job
    quit     chan bool
}

func NewWorkerPool(workerCount, queueSize int) *WorkerPool {
    ctx, cancel := context.WithCancel(context.Background())
    
    pool := &WorkerPool{
        workerCount: workerCount,
        jobQueue:    make(chan Job, queueSize),
        workers:     make([]*Worker, workerCount),
        ctx:         ctx,
        cancel:      cancel,
    }
    
    // åˆ›å»ºå·¥ä½œåç¨‹
    for i := 0; i < workerCount; i++ {
        worker := &Worker{
            id:       i,
            jobQueue: pool.jobQueue,
            quit:     make(chan bool),
        }
        pool.workers[i] = worker
    }
    
    return pool
}

func (p *WorkerPool) Start() {
    for _, worker := range p.workers {
        p.wg.Add(1)
        go func(w *Worker) {
            defer p.wg.Done()
            w.start(p.ctx)
        }(worker)
    }
}

func (p *WorkerPool) Submit(job Job) {
    select {
    case p.jobQueue <- job:
    case <-p.ctx.Done():
        // æ± å·²å…³é—­
    }
}

func (p *WorkerPool) Stop() {
    p.cancel()
    close(p.jobQueue)
    p.wg.Wait()
}

func (w *Worker) start(ctx context.Context) {
    for {
        select {
        case job := <-w.jobQueue:
            if job != nil {
                job()
            }
        case <-ctx.Done():
            return
        }
    }
}
```

### 5.3 éƒ¨ç½²ä¼˜åŒ–

#### å®¹å™¨èµ„æºé…ç½®
```yaml
# deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: sical-backend
spec:
  replicas: 3
  template:
    spec:
      containers:
      - name: sical-backend
        image: sical-backend:latest
        resources:
          requests:
            memory: "256Mi"
            cpu: "250m"
          limits:
            memory: "512Mi"
            cpu: "500m"
        env:
        - name: GOMAXPROCS
          valueFrom:
            resourceFieldRef:
              resource: limits.cpu
        - name: GOMEMLIMIT
          valueFrom:
            resourceFieldRef:
              resource: limits.memory
        livenessProbe:
          httpGet:
            path: /health
            port: 8080
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /ready
            port: 8080
          initialDelaySeconds: 5
          periodSeconds: 5
```

---

**æ–‡æ¡£ç»´æŠ¤**: æœ¬æ–‡æ¡£éšæ€§èƒ½ä¼˜åŒ–éœ€æ±‚æŒç»­æ›´æ–°  
**æœ€åæ›´æ–°**: 2024-01-15  
**è´Ÿè´£äºº**: æ€§èƒ½å·¥ç¨‹å¸ˆ