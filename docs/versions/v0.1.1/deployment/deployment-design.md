# æ™ºèƒ½å­¦ä¹ è§„åˆ’åº”ç”¨ - éƒ¨ç½²è®¾è®¡æ–‡æ¡£ v0.1.1

## ğŸ“‹ æ–‡æ¡£ä¿¡æ¯

| é¡¹ç›® | æ™ºèƒ½å­¦ä¹ è§„åˆ’åº”ç”¨ éƒ¨ç½²è®¾è®¡ |
|------|----------------------------|
| **ç‰ˆæœ¬** | v0.1.1 |
| **åç«¯æŠ€æœ¯** | Go + Gin + GORM |
| **æ›´æ–°æ—¥æœŸ** | 2024-01-15 |
| **çŠ¶æ€** | å¼€å‘ä¸­ |

## ğŸ—ï¸ éƒ¨ç½²æ¶æ„æ¦‚è§ˆ

### æ•´ä½“æ¶æ„å›¾
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        ç”¨æˆ·å±‚                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚   Webç”¨æˆ·   â”‚  â”‚  ç§»åŠ¨ç”¨æˆ·   â”‚  â”‚   APIç”¨æˆ·    â”‚        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                         Internet
                              â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        CDNå±‚                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚  CloudFlare â”‚  â”‚   é™æ€èµ„æº   â”‚  â”‚   å›¾ç‰‡CDN    â”‚        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      è´Ÿè½½å‡è¡¡å±‚                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚    Nginx    â”‚  â”‚  SSLç»ˆæ­¢    â”‚  â”‚   WAFé˜²æŠ¤    â”‚        â”‚
â”‚  â”‚ Load Balancerâ”‚  â”‚   Proxy     â”‚  â”‚  Firewall   â”‚        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      åº”ç”¨æœåŠ¡å±‚                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚  Go Backend â”‚  â”‚  Go Backend â”‚  â”‚  Go Backend â”‚        â”‚
â”‚  â”‚   Instance1 â”‚  â”‚   Instance2 â”‚  â”‚   Instance3 â”‚        â”‚
â”‚  â”‚  (Container)â”‚  â”‚  (Container)â”‚  â”‚  (Container)â”‚        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       ç¼“å­˜å±‚                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚ Redis Clusterâ”‚  â”‚ Redis Cache â”‚  â”‚ Redis Sessionâ”‚       â”‚
â”‚  â”‚   (ä¸»ä»)     â”‚  â”‚   (ç¼“å­˜)    â”‚  â”‚   (ä¼šè¯)     â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       æ•°æ®å±‚                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚ PostgreSQL  â”‚  â”‚ PostgreSQL  â”‚  â”‚   æ–‡ä»¶å­˜å‚¨   â”‚        â”‚
â”‚  â”‚   Master    â”‚  â”‚   Replica   â”‚  â”‚   MinIO/S3   â”‚        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      ç›‘æ§å±‚                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚ Prometheus  â”‚  â”‚   Grafana   â”‚  â”‚   ELK Stack â”‚        â”‚
â”‚  â”‚   ç›‘æ§      â”‚  â”‚   å¯è§†åŒ–    â”‚  â”‚   æ—¥å¿—      â”‚        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ³ å®¹å™¨åŒ–è®¾è®¡

### 2.1 Dockeré…ç½®

#### Dockerfile
```dockerfile
# å¤šé˜¶æ®µæ„å»º
FROM golang:1.21-alpine AS builder

# è®¾ç½®å·¥ä½œç›®å½•
WORKDIR /app

# å®‰è£…å¿…è¦çš„åŒ…
RUN apk add --no-cache git ca-certificates tzdata

# å¤åˆ¶go modæ–‡ä»¶
COPY go.mod go.sum ./

# ä¸‹è½½ä¾èµ–
RUN go mod download

# å¤åˆ¶æºä»£ç 
COPY . .

# æ„å»ºåº”ç”¨
RUN CGO_ENABLED=0 GOOS=linux go build -a -installsuffix cgo -o main ./cmd/server

# è¿è¡Œé˜¶æ®µ
FROM alpine:latest

# å®‰è£…caè¯ä¹¦å’Œæ—¶åŒºæ•°æ®
RUN apk --no-cache add ca-certificates tzdata

# è®¾ç½®æ—¶åŒº
ENV TZ=Asia/Shanghai

# åˆ›å»ºérootç”¨æˆ·
RUN addgroup -g 1001 -S appgroup && \
    adduser -u 1001 -S appuser -G appgroup

# è®¾ç½®å·¥ä½œç›®å½•
WORKDIR /root/

# ä»æ„å»ºé˜¶æ®µå¤åˆ¶äºŒè¿›åˆ¶æ–‡ä»¶
COPY --from=builder /app/main .
COPY --from=builder /app/configs ./configs
COPY --from=builder /app/migrations ./migrations

# æ›´æ”¹æ–‡ä»¶æ‰€æœ‰è€…
RUN chown -R appuser:appgroup /root

# åˆ‡æ¢åˆ°érootç”¨æˆ·
USER appuser

# æš´éœ²ç«¯å£
EXPOSE 8080

# å¥åº·æ£€æŸ¥
HEALTHCHECK --interval=30s --timeout=3s --start-period=5s --retries=3 \
    CMD wget --no-verbose --tries=1 --spider http://localhost:8080/health || exit 1

# å¯åŠ¨åº”ç”¨
CMD ["./main"]
```

#### Docker Compose (å¼€å‘ç¯å¢ƒ)
```yaml
version: '3.8'

services:
  # Goåç«¯æœåŠ¡
  backend:
    build:
      context: .
      dockerfile: Dockerfile
    ports:
      - "8080:8080"
    environment:
      - ENV=development
      - DB_HOST=postgres
      - DB_PORT=5432
      - DB_USER=sical_user
      - DB_PASSWORD=sical_password
      - DB_NAME=sical_db
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - JWT_SECRET=your-jwt-secret-key
    depends_on:
      - postgres
      - redis
    volumes:
      - ./logs:/app/logs
      - ./uploads:/app/uploads
    networks:
      - sical-network
    restart: unless-stopped

  # PostgreSQLæ•°æ®åº“
  postgres:
    image: postgres:15-alpine
    environment:
      - POSTGRES_DB=sical_db
      - POSTGRES_USER=sical_user
      - POSTGRES_PASSWORD=sical_password
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./scripts/init.sql:/docker-entrypoint-initdb.d/init.sql
    networks:
      - sical-network
    restart: unless-stopped

  # Redisç¼“å­˜
  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
      - ./configs/redis.conf:/usr/local/etc/redis/redis.conf
    command: redis-server /usr/local/etc/redis/redis.conf
    networks:
      - sical-network
    restart: unless-stopped

  # Nginxè´Ÿè½½å‡è¡¡
  nginx:
    image: nginx:alpine
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./configs/nginx.conf:/etc/nginx/nginx.conf
      - ./ssl:/etc/nginx/ssl
      - ./static:/usr/share/nginx/html
    depends_on:
      - backend
    networks:
      - sical-network
    restart: unless-stopped

  # Prometheusç›‘æ§
  prometheus:
    image: prom/prometheus:latest
    ports:
      - "9090:9090"
    volumes:
      - ./configs/prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
    networks:
      - sical-network
    restart: unless-stopped

  # Grafanaå¯è§†åŒ–
  grafana:
    image: grafana/grafana:latest
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin123
    volumes:
      - grafana_data:/var/lib/grafana
      - ./configs/grafana/dashboards:/etc/grafana/provisioning/dashboards
      - ./configs/grafana/datasources:/etc/grafana/provisioning/datasources
    networks:
      - sical-network
    restart: unless-stopped

volumes:
  postgres_data:
  redis_data:
  prometheus_data:
  grafana_data:

networks:
  sical-network:
    driver: bridge
```

### 2.2 Kubernetesé…ç½®

#### Namespace
```yaml
apiVersion: v1
kind: Namespace
metadata:
  name: sical
  labels:
    name: sical
    environment: production
```

#### ConfigMap
```yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: sical-config
  namespace: sical
data:
  app.env: |
    ENV=production
    LOG_LEVEL=info
    SERVER_PORT=8080
    DB_HOST=postgres-service
    DB_PORT=5432
    REDIS_HOST=redis-service
    REDIS_PORT=6379
    CACHE_TTL=3600
    JWT_EXPIRY=900
    REFRESH_TOKEN_EXPIRY=604800
```

#### Secret
```yaml
apiVersion: v1
kind: Secret
metadata:
  name: sical-secrets
  namespace: sical
type: Opaque
data:
  db-user: c2ljYWxfdXNlcg==  # base64 encoded
  db-password: c2ljYWxfcGFzc3dvcmQ=
  jwt-secret: eW91ci1qd3Qtc2VjcmV0LWtleQ==
  redis-password: cmVkaXNfcGFzc3dvcmQ=
```

#### Deployment
```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: sical-backend
  namespace: sical
  labels:
    app: sical-backend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: sical-backend
  template:
    metadata:
      labels:
        app: sical-backend
    spec:
      containers:
      - name: backend
        image: sical/backend:v0.1.1
        ports:
        - containerPort: 8080
        env:
        - name: DB_USER
          valueFrom:
            secretKeyRef:
              name: sical-secrets
              key: db-user
        - name: DB_PASSWORD
          valueFrom:
            secretKeyRef:
              name: sical-secrets
              key: db-password
        - name: JWT_SECRET
          valueFrom:
            secretKeyRef:
              name: sical-secrets
              key: jwt-secret
        envFrom:
        - configMapRef:
            name: sical-config
        resources:
          requests:
            memory: "256Mi"
            cpu: "250m"
          limits:
            memory: "512Mi"
            cpu: "500m"
        livenessProbe:
          httpGet:
            path: /health
            port: 8080
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /ready
            port: 8080
          initialDelaySeconds: 5
          periodSeconds: 5
        volumeMounts:
        - name: logs
          mountPath: /app/logs
        - name: uploads
          mountPath: /app/uploads
      volumes:
      - name: logs
        persistentVolumeClaim:
          claimName: sical-logs-pvc
      - name: uploads
        persistentVolumeClaim:
          claimName: sical-uploads-pvc
      imagePullSecrets:
      - name: registry-secret
---
apiVersion: v1
kind: Service
metadata:
  name: sical-backend-service
  namespace: sical
spec:
  selector:
    app: sical-backend
  ports:
  - protocol: TCP
    port: 80
    targetPort: 8080
  type: ClusterIP
```

#### HorizontalPodAutoscaler
```yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: sical-backend-hpa
  namespace: sical
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: sical-backend
  minReplicas: 3
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80
```

## ğŸš€ CI/CDæµç¨‹

### 3.1 GitHub Actionsé…ç½®

#### ä¸»å·¥ä½œæµ
```yaml
name: CI/CD Pipeline

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]

env:
  REGISTRY: ghcr.io
  IMAGE_NAME: sical/backend

jobs:
  # ä»£ç è´¨é‡æ£€æŸ¥
  lint-and-test:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Go
      uses: actions/setup-go@v4
      with:
        go-version: '1.21'
    
    - name: Cache Go modules
      uses: actions/cache@v3
      with:
        path: ~/go/pkg/mod
        key: ${{ runner.os }}-go-${{ hashFiles('**/go.sum') }}
        restore-keys: |
          ${{ runner.os }}-go-
    
    - name: Install dependencies
      run: go mod download
    
    - name: Run golangci-lint
      uses: golangci/golangci-lint-action@v3
      with:
        version: latest
        args: --timeout=5m
    
    - name: Run tests
      run: |
        go test -v -race -coverprofile=coverage.out ./...
        go tool cover -html=coverage.out -o coverage.html
    
    - name: Upload coverage reports
      uses: codecov/codecov-action@v3
      with:
        file: ./coverage.out
        flags: unittests
        name: codecov-umbrella
    
    - name: Security scan
      uses: securecodewarrior/github-action-add-sarif@v1
      with:
        sarif-file: 'gosec-report.sarif'

  # æ„å»ºå’Œæ¨é€é•œåƒ
  build-and-push:
    needs: lint-and-test
    runs-on: ubuntu-latest
    if: github.event_name == 'push'
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v3
    
    - name: Log in to Container Registry
      uses: docker/login-action@v3
      with:
        registry: ${{ env.REGISTRY }}
        username: ${{ github.actor }}
        password: ${{ secrets.GITHUB_TOKEN }}
    
    - name: Extract metadata
      id: meta
      uses: docker/metadata-action@v5
      with:
        images: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}
        tags: |
          type=ref,event=branch
          type=ref,event=pr
          type=sha,prefix={{branch}}-
          type=raw,value=latest,enable={{is_default_branch}}
    
    - name: Build and push Docker image
      uses: docker/build-push-action@v5
      with:
        context: .
        platforms: linux/amd64,linux/arm64
        push: true
        tags: ${{ steps.meta.outputs.tags }}
        labels: ${{ steps.meta.outputs.labels }}
        cache-from: type=gha
        cache-to: type=gha,mode=max

  # éƒ¨ç½²åˆ°å¼€å‘ç¯å¢ƒ
  deploy-dev:
    needs: build-and-push
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/develop'
    environment: development
    steps:
    - uses: actions/checkout@v4
    
    - name: Deploy to Development
      run: |
        echo "Deploying to development environment"
        # è¿™é‡Œæ·»åŠ éƒ¨ç½²è„šæœ¬

  # éƒ¨ç½²åˆ°ç”Ÿäº§ç¯å¢ƒ
  deploy-prod:
    needs: build-and-push
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'
    environment: production
    steps:
    - uses: actions/checkout@v4
    
    - name: Deploy to Production
      run: |
        echo "Deploying to production environment"
        # è¿™é‡Œæ·»åŠ ç”Ÿäº§éƒ¨ç½²è„šæœ¬
```

### 3.2 éƒ¨ç½²è„šæœ¬

#### éƒ¨ç½²è„šæœ¬ (deploy.sh)
```bash
#!/bin/bash

set -e

# é…ç½®å˜é‡
ENVIRONMENT=${1:-development}
IMAGE_TAG=${2:-latest}
NAMESPACE="sical-${ENVIRONMENT}"

echo "Deploying to ${ENVIRONMENT} environment with image tag ${IMAGE_TAG}"

# æ£€æŸ¥kubectlè¿æ¥
if ! kubectl cluster-info &> /dev/null; then
    echo "Error: Cannot connect to Kubernetes cluster"
    exit 1
fi

# åˆ›å»ºå‘½åç©ºé—´ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
kubectl create namespace ${NAMESPACE} --dry-run=client -o yaml | kubectl apply -f -

# æ›´æ–°é•œåƒæ ‡ç­¾
kubectl set image deployment/sical-backend backend=ghcr.io/sical/backend:${IMAGE_TAG} -n ${NAMESPACE}

# ç­‰å¾…éƒ¨ç½²å®Œæˆ
kubectl rollout status deployment/sical-backend -n ${NAMESPACE} --timeout=300s

# éªŒè¯éƒ¨ç½²
echo "Verifying deployment..."
kubectl get pods -n ${NAMESPACE} -l app=sical-backend

# è¿è¡Œå¥åº·æ£€æŸ¥
echo "Running health check..."
SERVICE_URL=$(kubectl get service sical-backend-service -n ${NAMESPACE} -o jsonpath='{.status.loadBalancer.ingress[0].ip}')
if [ -n "$SERVICE_URL" ]; then
    curl -f http://${SERVICE_URL}/health || {
        echo "Health check failed"
        exit 1
    }
    echo "Deployment successful!"
else
    echo "Warning: Could not get service URL for health check"
fi
```

#### æ•°æ®åº“è¿ç§»è„šæœ¬
```bash
#!/bin/bash

set -e

ENVIRONMENT=${1:-development}
NAMESPACE="sical-${ENVIRONMENT}"

echo "Running database migrations for ${ENVIRONMENT}"

# åˆ›å»ºè¿ç§»Job
cat <<EOF | kubectl apply -f -
apiVersion: batch/v1
kind: Job
metadata:
  name: db-migration-$(date +%s)
  namespace: ${NAMESPACE}
spec:
  template:
    spec:
      containers:
      - name: migration
        image: ghcr.io/sical/backend:latest
        command: ["./main", "migrate"]
        env:
        - name: DB_USER
          valueFrom:
            secretKeyRef:
              name: sical-secrets
              key: db-user
        - name: DB_PASSWORD
          valueFrom:
            secretKeyRef:
              name: sical-secrets
              key: db-password
        envFrom:
        - configMapRef:
            name: sical-config
      restartPolicy: Never
  backoffLimit: 3
EOF

echo "Migration job created"
```

## ğŸ“Š ç›‘æ§ä¸æ—¥å¿—

### 4.1 Prometheusç›‘æ§é…ç½®

#### prometheus.yml
```yaml
global:
  scrape_interval: 15s
  evaluation_interval: 15s

rule_files:
  - "alert_rules.yml"

alerting:
  alertmanagers:
    - static_configs:
        - targets:
          - alertmanager:9093

scrape_configs:
  # Prometheusè‡ªèº«ç›‘æ§
  - job_name: 'prometheus'
    static_configs:
      - targets: ['localhost:9090']

  # Goåº”ç”¨ç›‘æ§
  - job_name: 'sical-backend'
    kubernetes_sd_configs:
      - role: pod
        namespaces:
          names:
            - sical
    relabel_configs:
      - source_labels: [__meta_kubernetes_pod_label_app]
        action: keep
        regex: sical-backend
      - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
        action: keep
        regex: true
      - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]
        action: replace
        target_label: __metrics_path__
        regex: (.+)

  # PostgreSQLç›‘æ§
  - job_name: 'postgres'
    static_configs:
      - targets: ['postgres-exporter:9187']

  # Redisç›‘æ§
  - job_name: 'redis'
    static_configs:
      - targets: ['redis-exporter:9121']

  # Nginxç›‘æ§
  - job_name: 'nginx'
    static_configs:
      - targets: ['nginx-exporter:9113']
```

#### å‘Šè­¦è§„åˆ™ (alert_rules.yml)
```yaml
groups:
- name: sical-backend
  rules:
  # é«˜é”™è¯¯ç‡å‘Šè­¦
  - alert: HighErrorRate
    expr: rate(http_requests_total{status=~"5.."}[5m]) > 0.1
    for: 5m
    labels:
      severity: critical
    annotations:
      summary: "High error rate detected"
      description: "Error rate is {{ $value }} errors per second"

  # é«˜å“åº”æ—¶é—´å‘Šè­¦
  - alert: HighResponseTime
    expr: histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m])) > 1
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "High response time detected"
      description: "95th percentile response time is {{ $value }} seconds"

  # å†…å­˜ä½¿ç”¨ç‡å‘Šè­¦
  - alert: HighMemoryUsage
    expr: (process_resident_memory_bytes / 1024 / 1024) > 400
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "High memory usage detected"
      description: "Memory usage is {{ $value }} MB"

  # CPUä½¿ç”¨ç‡å‘Šè­¦
  - alert: HighCPUUsage
    expr: rate(process_cpu_seconds_total[5m]) * 100 > 80
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "High CPU usage detected"
      description: "CPU usage is {{ $value }}%"

  # æ•°æ®åº“è¿æ¥å‘Šè­¦
  - alert: DatabaseConnectionFailure
    expr: up{job="postgres"} == 0
    for: 1m
    labels:
      severity: critical
    annotations:
      summary: "Database connection failure"
      description: "Cannot connect to PostgreSQL database"

  # Redisè¿æ¥å‘Šè­¦
  - alert: RedisConnectionFailure
    expr: up{job="redis"} == 0
    for: 1m
    labels:
      severity: critical
    annotations:
      summary: "Redis connection failure"
      description: "Cannot connect to Redis cache"
```

### 4.2 åº”ç”¨ç›‘æ§æŒ‡æ ‡

#### Goåº”ç”¨ç›‘æ§ä»£ç 
```go
package monitoring

import (
    "github.com/gin-gonic/gin"
    "github.com/prometheus/client_golang/prometheus"
    "github.com/prometheus/client_golang/prometheus/promauto"
    "github.com/prometheus/client_golang/prometheus/promhttp"
    "strconv"
    "time"
)

// å®šä¹‰ç›‘æ§æŒ‡æ ‡
var (
    // HTTPè¯·æ±‚æ€»æ•°
    httpRequestsTotal = promauto.NewCounterVec(
        prometheus.CounterOpts{
            Name: "http_requests_total",
            Help: "Total number of HTTP requests",
        },
        []string{"method", "endpoint", "status"},
    )

    // HTTPè¯·æ±‚æŒç»­æ—¶é—´
    httpRequestDuration = promauto.NewHistogramVec(
        prometheus.HistogramOpts{
            Name:    "http_request_duration_seconds",
            Help:    "HTTP request duration in seconds",
            Buckets: prometheus.DefBuckets,
        },
        []string{"method", "endpoint"},
    )

    // æ´»è·ƒè¿æ¥æ•°
    activeConnections = promauto.NewGauge(
        prometheus.GaugeOpts{
            Name: "active_connections",
            Help: "Number of active connections",
        },
    )

    // æ•°æ®åº“æŸ¥è¯¢æŒç»­æ—¶é—´
    dbQueryDuration = promauto.NewHistogramVec(
        prometheus.HistogramOpts{
            Name:    "db_query_duration_seconds",
            Help:    "Database query duration in seconds",
            Buckets: []float64{0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 2, 5},
        },
        []string{"operation", "table"},
    )

    // ç¼“å­˜å‘½ä¸­ç‡
    cacheHits = promauto.NewCounterVec(
        prometheus.CounterOpts{
            Name: "cache_hits_total",
            Help: "Total number of cache hits",
        },
        []string{"cache_type"},
    )

    cacheMisses = promauto.NewCounterVec(
        prometheus.CounterOpts{
            Name: "cache_misses_total",
            Help: "Total number of cache misses",
        },
        []string{"cache_type"},
    )
)

// Prometheusä¸­é—´ä»¶
func PrometheusMiddleware() gin.HandlerFunc {
    return func(c *gin.Context) {
        start := time.Now()
        
        // å¢åŠ æ´»è·ƒè¿æ¥æ•°
        activeConnections.Inc()
        defer activeConnections.Dec()
        
        // å¤„ç†è¯·æ±‚
        c.Next()
        
        // è®°å½•æŒ‡æ ‡
        duration := time.Since(start).Seconds()
        status := strconv.Itoa(c.Writer.Status())
        
        httpRequestsTotal.WithLabelValues(
            c.Request.Method,
            c.FullPath(),
            status,
        ).Inc()
        
        httpRequestDuration.WithLabelValues(
            c.Request.Method,
            c.FullPath(),
        ).Observe(duration)
    }
}

// æ•°æ®åº“ç›‘æ§è£…é¥°å™¨
func MonitorDBQuery(operation, table string, fn func() error) error {
    start := time.Now()
    err := fn()
    duration := time.Since(start).Seconds()
    
    dbQueryDuration.WithLabelValues(operation, table).Observe(duration)
    return err
}

// ç¼“å­˜ç›‘æ§
func RecordCacheHit(cacheType string) {
    cacheHits.WithLabelValues(cacheType).Inc()
}

func RecordCacheMiss(cacheType string) {
    cacheMisses.WithLabelValues(cacheType).Inc()
}

// æ³¨å†ŒPrometheuså¤„ç†å™¨
func RegisterPrometheusHandler(router *gin.Engine) {
    router.GET("/metrics", gin.WrapH(promhttp.Handler()))
}
```

### 4.3 æ—¥å¿—ç®¡ç†

#### ç»“æ„åŒ–æ—¥å¿—é…ç½®
```go
package logger

import (
    "os"
    "time"
    
    "go.uber.org/zap"
    "go.uber.org/zap/zapcore"
    "gopkg.in/natefinch/lumberjack.v2"
)

type Logger struct {
    *zap.Logger
}

func NewLogger(env string) (*Logger, error) {
    var config zap.Config
    
    if env == "production" {
        config = zap.NewProductionConfig()
        config.Level = zap.NewAtomicLevelAt(zap.InfoLevel)
    } else {
        config = zap.NewDevelopmentConfig()
        config.Level = zap.NewAtomicLevelAt(zap.DebugLevel)
    }
    
    // è‡ªå®šä¹‰ç¼–ç å™¨é…ç½®
    config.EncoderConfig = zapcore.EncoderConfig{
        TimeKey:        "timestamp",
        LevelKey:       "level",
        NameKey:        "logger",
        CallerKey:      "caller",
        MessageKey:     "message",
        StacktraceKey:  "stacktrace",
        LineEnding:     zapcore.DefaultLineEnding,
        EncodeLevel:    zapcore.LowercaseLevelEncoder,
        EncodeTime:     zapcore.ISO8601TimeEncoder,
        EncodeDuration: zapcore.StringDurationEncoder,
        EncodeCaller:   zapcore.ShortCallerEncoder,
    }
    
    // é…ç½®è¾“å‡º
    var cores []zapcore.Core
    
    // æ§åˆ¶å°è¾“å‡º
    consoleEncoder := zapcore.NewConsoleEncoder(config.EncoderConfig)
    consoleCore := zapcore.NewCore(
        consoleEncoder,
        zapcore.AddSync(os.Stdout),
        config.Level,
    )
    cores = append(cores, consoleCore)
    
    // æ–‡ä»¶è¾“å‡ºï¼ˆç”Ÿäº§ç¯å¢ƒï¼‰
    if env == "production" {
        fileEncoder := zapcore.NewJSONEncoder(config.EncoderConfig)
        
        // åº”ç”¨æ—¥å¿—
        appLogWriter := &lumberjack.Logger{
            Filename:   "/app/logs/app.log",
            MaxSize:    100, // MB
            MaxBackups: 10,
            MaxAge:     30, // days
            Compress:   true,
        }
        
        appCore := zapcore.NewCore(
            fileEncoder,
            zapcore.AddSync(appLogWriter),
            config.Level,
        )
        cores = append(cores, appCore)
        
        // é”™è¯¯æ—¥å¿—
        errorLogWriter := &lumberjack.Logger{
            Filename:   "/app/logs/error.log",
            MaxSize:    100,
            MaxBackups: 10,
            MaxAge:     30,
            Compress:   true,
        }
        
        errorCore := zapcore.NewCore(
            fileEncoder,
            zapcore.AddSync(errorLogWriter),
            zap.ErrorLevel,
        )
        cores = append(cores, errorCore)
    }
    
    // åˆ›å»ºlogger
    core := zapcore.NewTee(cores...)
    logger := zap.New(core, zap.AddCaller(), zap.AddStacktrace(zap.ErrorLevel))
    
    return &Logger{logger}, nil
}

// è¯·æ±‚æ—¥å¿—ä¸­é—´ä»¶
func (l *Logger) GinLogger() gin.HandlerFunc {
    return gin.LoggerWithFormatter(func(param gin.LogFormatterParams) string {
        l.Info("HTTP Request",
            zap.String("method", param.Method),
            zap.String("path", param.Path),
            zap.Int("status", param.StatusCode),
            zap.Duration("latency", param.Latency),
            zap.String("client_ip", param.ClientIP),
            zap.String("user_agent", param.Request.UserAgent()),
            zap.String("error", param.ErrorMessage),
        )
        return ""
    })
}

// æ¢å¤ä¸­é—´ä»¶
func (l *Logger) GinRecovery() gin.HandlerFunc {
    return gin.RecoveryWithWriter(os.Stderr, func(c *gin.Context, recovered interface{}) {
        l.Error("Panic recovered",
            zap.Any("error", recovered),
            zap.String("path", c.Request.URL.Path),
            zap.String("method", c.Request.Method),
        )
        c.AbortWithStatus(http.StatusInternalServerError)
    })
}
```

## ğŸ”§ è¿ç»´ç®¡ç†

### 5.1 å¥åº·æ£€æŸ¥

#### å¥åº·æ£€æŸ¥ç«¯ç‚¹
```go
package health

import (
    "context"
    "database/sql"
    "net/http"
    "time"
    
    "github.com/gin-gonic/gin"
    "github.com/go-redis/redis/v8"
)

type HealthChecker struct {
    db    *sql.DB
    redis *redis.Client
}

type HealthStatus struct {
    Status    string            `json:"status"`
    Timestamp time.Time         `json:"timestamp"`
    Services  map[string]string `json:"services"`
    Version   string            `json:"version"`
    Uptime    time.Duration     `json:"uptime"`
}

func NewHealthChecker(db *sql.DB, redis *redis.Client) *HealthChecker {
    return &HealthChecker{
        db:    db,
        redis: redis,
    }
}

func (hc *HealthChecker) HealthCheck(c *gin.Context) {
    status := &HealthStatus{
        Status:    "healthy",
        Timestamp: time.Now(),
        Services:  make(map[string]string),
        Version:   "v0.1.1",
        Uptime:    time.Since(startTime),
    }
    
    // æ£€æŸ¥æ•°æ®åº“
    if err := hc.checkDatabase(); err != nil {
        status.Services["database"] = "unhealthy: " + err.Error()
        status.Status = "unhealthy"
    } else {
        status.Services["database"] = "healthy"
    }
    
    // æ£€æŸ¥Redis
    if err := hc.checkRedis(); err != nil {
        status.Services["redis"] = "unhealthy: " + err.Error()
        status.Status = "unhealthy"
    } else {
        status.Services["redis"] = "healthy"
    }
    
    httpStatus := http.StatusOK
    if status.Status == "unhealthy" {
        httpStatus = http.StatusServiceUnavailable
    }
    
    c.JSON(httpStatus, status)
}

func (hc *HealthChecker) ReadinessCheck(c *gin.Context) {
    // ç®€å•çš„å°±ç»ªæ£€æŸ¥
    c.JSON(http.StatusOK, gin.H{
        "status": "ready",
        "timestamp": time.Now(),
    })
}

func (hc *HealthChecker) checkDatabase() error {
    ctx, cancel := context.WithTimeout(context.Background(), 5*time.Second)
    defer cancel()
    
    return hc.db.PingContext(ctx)
}

func (hc *HealthChecker) checkRedis() error {
    ctx, cancel := context.WithTimeout(context.Background(), 5*time.Second)
    defer cancel()
    
    return hc.redis.Ping(ctx).Err()
}
```

### 5.2 å¤‡ä»½ç­–ç•¥

#### æ•°æ®åº“å¤‡ä»½è„šæœ¬
```bash
#!/bin/bash

set -e

# é…ç½®
BACKUP_DIR="/backups/postgres"
RETENTION_DAYS=30
DATE=$(date +%Y%m%d_%H%M%S)
BACKUP_FILE="sical_backup_${DATE}.sql"

# åˆ›å»ºå¤‡ä»½ç›®å½•
mkdir -p ${BACKUP_DIR}

# æ‰§è¡Œå¤‡ä»½
echo "Starting database backup..."
pg_dump -h ${DB_HOST} -U ${DB_USER} -d ${DB_NAME} > ${BACKUP_DIR}/${BACKUP_FILE}

# å‹ç¼©å¤‡ä»½æ–‡ä»¶
gzip ${BACKUP_DIR}/${BACKUP_FILE}

# æ¸…ç†æ—§å¤‡ä»½
find ${BACKUP_DIR} -name "*.gz" -mtime +${RETENTION_DAYS} -delete

echo "Backup completed: ${BACKUP_FILE}.gz"

# éªŒè¯å¤‡ä»½
if [ -f "${BACKUP_DIR}/${BACKUP_FILE}.gz" ]; then
    echo "Backup verification successful"
else
    echo "Backup verification failed"
    exit 1
fi
```

#### Kubernetes CronJobå¤‡ä»½
```yaml
apiVersion: batch/v1
kind: CronJob
metadata:
  name: postgres-backup
  namespace: sical
spec:
  schedule: "0 2 * * *"  # æ¯å¤©å‡Œæ™¨2ç‚¹
  jobTemplate:
    spec:
      template:
        spec:
          containers:
          - name: postgres-backup
            image: postgres:15-alpine
            command:
            - /bin/bash
            - -c
            - |
              pg_dump -h $DB_HOST -U $DB_USER -d $DB_NAME | gzip > /backup/sical_backup_$(date +%Y%m%d_%H%M%S).sql.gz
            env:
            - name: DB_HOST
              value: "postgres-service"
            - name: DB_USER
              valueFrom:
                secretKeyRef:
                  name: sical-secrets
                  key: db-user
            - name: PGPASSWORD
              valueFrom:
                secretKeyRef:
                  name: sical-secrets
                  key: db-password
            volumeMounts:
            - name: backup-storage
              mountPath: /backup
          volumes:
          - name: backup-storage
            persistentVolumeClaim:
              claimName: backup-pvc
          restartPolicy: OnFailure
```

### 5.3 æ€§èƒ½è°ƒä¼˜

#### åº”ç”¨æ€§èƒ½é…ç½®
```go
package config

import (
    "runtime"
    "time"
)

type PerformanceConfig struct {
    // HTTPæœåŠ¡å™¨é…ç½®
    ReadTimeout       time.Duration
    WriteTimeout      time.Duration
    IdleTimeout       time.Duration
    ReadHeaderTimeout time.Duration
    MaxHeaderBytes    int
    
    // æ•°æ®åº“è¿æ¥æ± é…ç½®
    MaxOpenConns    int
    MaxIdleConns    int
    ConnMaxLifetime time.Duration
    ConnMaxIdleTime time.Duration
    
    // Redisé…ç½®
    PoolSize     int
    MinIdleConns int
    PoolTimeout  time.Duration
    
    // åº”ç”¨é…ç½®
    WorkerPoolSize int
    QueueSize      int
    CacheSize      int
}

func NewPerformanceConfig() *PerformanceConfig {
    return &PerformanceConfig{
        // HTTPæœåŠ¡å™¨
        ReadTimeout:       30 * time.Second,
        WriteTimeout:      30 * time.Second,
        IdleTimeout:       120 * time.Second,
        ReadHeaderTimeout: 10 * time.Second,
        MaxHeaderBytes:    1 << 20, // 1MB
        
        // æ•°æ®åº“è¿æ¥æ± 
        MaxOpenConns:    25,
        MaxIdleConns:    5,
        ConnMaxLifetime: time.Hour,
        ConnMaxIdleTime: 10 * time.Minute,
        
        // Redis
        PoolSize:     10,
        MinIdleConns: 2,
        PoolTimeout:  4 * time.Second,
        
        // åº”ç”¨
        WorkerPoolSize: runtime.NumCPU() * 2,
        QueueSize:      1000,
        CacheSize:      10000,
    }
}
```

---

**æ–‡æ¡£ç»´æŠ¤**: æœ¬æ–‡æ¡£éšéƒ¨ç½²éœ€æ±‚å˜åŒ–æŒç»­æ›´æ–°  
**æœ€åæ›´æ–°**: 2024-01-15  
**è´Ÿè´£äºº**: DevOpså·¥ç¨‹å¸ˆ